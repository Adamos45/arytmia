from feature_extraction import read_data
from wfdb.processing import xqrs_detect
import numpy as np
from symbols_enums import FeatureNames
from features_calculation import features_calculation
import joblib
from scoring import scorer
from preprocessing import preprocessing
import pandas
from sklearn.preprocessing import StandardScaler


def program_exploitation(record):
    feature_names = [FeatureNames.mvsk, FeatureNames.db5,
                     FeatureNames.db6, FeatureNames.diffs]

    beats = xqrs_detect(record, 360, verbose=False)
    record = preprocessing(record, True)
    scaler = StandardScaler()

    data = []
    for feature in feature_names:
        data.append(features_calculation(record, beats, feature, True))
    models = []
    for feature in feature_names:
        models.append(joblib.load("./trained_models/" + feature.value + ".sav"))
    predictions = []
    for i, feature in enumerate(feature_names):
        test_features = scaler.fit_transform(data[i]).astype(np.float64)
        if feature == FeatureNames.diffs:
            predictions.append(scorer(X=test_features, estimator=models[i], diffs=True))
        else:
            predictions.append(scorer(X=test_features, estimator=models[i]))

    ensembled_prediction = []
    for i in range(len(predictions[0])):
        voting = np.array(np.zeros(shape=(len(feature_names), 4)))
        for j in range(len(predictions)):
            voting[j] = predictions[j][i]
        voting = voting.T
        products = np.array(np.zeros(shape=4))
        for p in range(len(products)):
            products[p] = np.product(voting[p])
        ensembled_prediction.append(np.argmax(products))
    return ensembled_prediction
